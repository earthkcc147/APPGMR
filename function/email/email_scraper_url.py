# ‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö

# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
import re  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Å‡∏±‡∏ö Regular Expression
import requests  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠ HTTP ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
from urllib.parse import urlsplit  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á URL
from collections import deque  # ‡∏Ñ‡∏≠‡∏ô‡πÄ‡∏ó‡∏ô‡πÄ‡∏ô‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Å‡∏±‡∏ö‡∏•‡∏¥‡∏™‡∏ï‡πå

# ‡πÅ‡∏û‡πá‡∏Ñ‡πÄ‡∏Å‡∏à Python ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ HTML ‡πÅ‡∏•‡∏∞ XML
from bs4 import BeautifulSoup
import requests.exceptions  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏¢‡∏Å‡πÄ‡∏ß‡πâ‡∏ô

# ‡πÉ‡∏™‡πà URL ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ original_url
original_url = input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Å‡∏£‡∏≠‡∏Å URL ‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö: ")

# ‡∏Ñ‡∏¥‡∏ß‡∏Ç‡∏≠‡∏á URL ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
unprocessed_urls = deque([original_url])

# ‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡∏≠‡∏á URL ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß
processed_urls = set()

# ‡πÄ‡∏ã‡πá‡∏ï‡∏Ç‡∏≠‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ
emails = set()

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏î‡∏∂‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå...")

# ‡∏¢‡πâ‡∏≤‡∏¢ URL ‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏Ñ‡∏¥‡∏ß‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ã‡πá‡∏ï‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡πâ‡∏ß
url = unprocessed_urls.popleft()
# ‡∏•‡∏ö‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏î‡πâ‡∏≤‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á deque
processed_urls.add(url)

# ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á URL ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô relative
parts = urlsplit(url)

# ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å urlsplit() ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏π‡πÄ‡∏û‡∏¥‡∏•‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ (schema, network location, path, query, fragment)
# ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏ß‡∏ô base ‡πÅ‡∏•‡∏∞ path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö URL ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
base_url = "{0.scheme}://{0.netloc}".format(parts)
path = url[: url.rfind("/") + 1] if "/" in parts.path else url

# ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏Ç‡∏≠ HTTP GET ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå
try:
    response = requests.get(url)
except (requests.exceptions.MissingSchema, requests.exceptions.ConnectionError):
    # ‡∏Ç‡πâ‡∏≤‡∏°‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÅ‡∏•‡∏∞‡πÑ‡∏õ‡∏¢‡∏±‡∏á URL ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
    pass

# ‡∏î‡∏∂‡∏á‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡πÅ‡∏•‡∏∞‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô‡πÄ‡∏ã‡πá‡∏ï
new_emails = set(
    re.findall(r"[a-z0-9\.\-+_]+@[a-z0-9\.\-+_]+\.[a-z]+", response.text, re.I)
)
emails.update(new_emails)

# ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÑ‡∏î‡πâ
if emails:
    print("\nüìß ‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏ó‡∏µ‡πà‡∏û‡∏ö‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡πá‡∏ö‡πÑ‡∏ã‡∏ï‡πå:")
    for email in emails:
        print(f"‚û°Ô∏è {email}")
else:
    print("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö‡∏ô‡∏µ‡πâ.")

# ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏∏‡∏Å URL ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡πÉ‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏ß‡πá‡∏ö
# ‡∏™‡∏£‡πâ‡∏≤‡∏á BeautifulSoup ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ HTML
soup = BeautifulSoup(response.text, "html.parser")

# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡πÅ‡∏¢‡∏Å‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
# ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏ó‡∏∏‡∏Å ‡πÜ ‡πÅ‡∏ó‡πá‡∏Å anchor (<a>) ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏•‡∏¥‡∏á‡∏Å‡πå‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á
for anchor in soup.find_all("a"):
    # ‡∏î‡∏∂‡∏á‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏à‡∏≤‡∏Å‡πÅ‡∏ó‡πá‡∏Å anchor
    link = anchor.attrs["href"] if "href" in anchor.attrs else ""
    # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô relative (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ /)
    if link.startswith("/"):
        link = base_url + link
    elif not link.startswith("http"):
        link = path + link

    # ‡πÄ‡∏û‡∏¥‡πà‡∏° URL ‡πÉ‡∏´‡∏°‡πà‡∏•‡∏á‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏¥‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ô‡πÄ‡∏ã‡πá‡∏ï‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÅ‡∏•‡πâ‡∏ß
    if not link in unprocessed_urls and not link in processed_urls:
        unprocessed_urls.append(link)

# ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
print("\nüîÑ ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πå‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß!")
print("üöÄ ‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£.")